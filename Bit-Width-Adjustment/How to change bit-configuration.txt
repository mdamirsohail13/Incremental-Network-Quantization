issue #6 https://github.com/Zhouaojun/Incremental-Network-Quantization/issues/6
======================================================================================
Question => Is it possible to adjust the bit-width by changing the number 7?
In power2.cpp

template
double weightCluster_zero( Dtype weight, int M)
{
double min=100;
double ind=0;
double flag=1.0;
if(min>std::abs(weight))
{
min=std::abs(weight);
flag=0.0;
}

for(int i=(M-7);i<=M;i++)
  {
    if(min>std::abs(weight-pow(2,i)))
      {
        min=std::abs(weight-pow(2,i));
        ind=i;
        flag=1.0;
      }
    if(min>std::abs(weight+pow(2,i)))
      {
        min=std::abs(weight+pow(2,i));
        ind=i;
        flag=-1.0;
      }
  }
  return flag*pow(2,ind);

}

it looks like this equation [ Wl(i, j) = βsgn(Wl(i, j)) if(α+β)/2≤abs(Wl(i, j))<3β/2 ]
======================================================================================
Author: yes, 
the number 7 (default) is corresponding to 5 bits in paper, you can modify it,
 3 => 4 bits,
 1 => 3 bits,
 0 => 2 bits.
=====================================================================================
Question => if i want to train 16 bit or 8 bit，how to set the number？Thanks
i compute the number (eg. -7) by 1-2^(5-2), Is that correct?
=====================================================================================
Author: 
n2 = n1 + 1 −2^(b−1)/2. 

For instance, 
 if b = 3 and n1 = −1, it is easy to get n2 = −2,
 if b=5, n2=-1+1-(2^(5-1))/2=-8
=====================================================================================
